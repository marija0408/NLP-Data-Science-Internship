{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bca440e",
   "metadata": {},
   "source": [
    "1.Take any csv/text file of 2+ GB of your choice. --- (You can do this assignment on Google colab)\n",
    "\n",
    "2.Read the file ( Dask, Modin, Ray, pandas and present your findings in term of computational efficiency )\n",
    "\n",
    "3.Perform basic validation on data columns : eg: remove special character , white spaces from the col name\n",
    "\n",
    "4.As you already know the schema hence create a YAML file and write the column name in YAML file. --define separator of\n",
    "read and write file, column name in YAML\n",
    "\n",
    "5.Validate number of columns and column name of ingested file with YAML.\n",
    "\n",
    "6.Write the file in pipe separated text file (|) in gz format.\n",
    "\n",
    "7.Create a summary of the file:\n",
    "\n",
    "Total number of rows,\n",
    "\n",
    "total number of columns\n",
    "\n",
    "file size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34d5dd",
   "metadata": {},
   "source": [
    "1.Take any csv/text file of 2+ GB of your choice. \n",
    "\n",
    "I have found a 3.49GB file on kaggle: https://www.kaggle.com/code/souamesannis/tips-to-work-efficiently-with-the-dataset/data?select=transactions_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b038e328",
   "metadata": {},
   "source": [
    "2.Read the file ( Dask, Modin, Ray, pandas and present your findings in term of computational efficiency )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import modin.pandas as mpd\n",
    "import re\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b49bf1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 27s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_pandas = pd.read_csv('transactions_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "813625a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 79.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_dask = dd.read_csv('transactions_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85a4607c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 8s\n",
      "Wall time: 46.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>663713001</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>541518023</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>505221004</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>685687003</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>685687004</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588586</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>fff2282977442e327b45d8c89afde25617d00124d0f999...</td>\n",
       "      <td>929511001</td>\n",
       "      <td>0.059305</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588587</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>fff2282977442e327b45d8c89afde25617d00124d0f999...</td>\n",
       "      <td>891322004</td>\n",
       "      <td>0.042356</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588588</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>fff380805474b287b05cb2a7507b9a013482f7dd0bce0e...</td>\n",
       "      <td>918325001</td>\n",
       "      <td>0.043203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588589</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>fff4d3a8b1f3b60af93e78c30a7cb4cf75edaf2590d3e5...</td>\n",
       "      <td>833459002</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588590</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>fffef3b6b73545df065b521e19f64bf6fe93bfd450ab20...</td>\n",
       "      <td>898573003</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31788324 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             t_dat                                        customer_id  \\\n",
       "0       2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "1       2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "2       2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   \n",
       "3       2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   \n",
       "4       2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   \n",
       "...            ...                                                ...   \n",
       "588586  2020-09-22  fff2282977442e327b45d8c89afde25617d00124d0f999...   \n",
       "588587  2020-09-22  fff2282977442e327b45d8c89afde25617d00124d0f999...   \n",
       "588588  2020-09-22  fff380805474b287b05cb2a7507b9a013482f7dd0bce0e...   \n",
       "588589  2020-09-22  fff4d3a8b1f3b60af93e78c30a7cb4cf75edaf2590d3e5...   \n",
       "588590  2020-09-22  fffef3b6b73545df065b521e19f64bf6fe93bfd450ab20...   \n",
       "\n",
       "        article_id     price  sales_channel_id  \n",
       "0        663713001  0.050831                 2  \n",
       "1        541518023  0.030492                 2  \n",
       "2        505221004  0.015237                 2  \n",
       "3        685687003  0.016932                 2  \n",
       "4        685687004  0.016932                 2  \n",
       "...            ...       ...               ...  \n",
       "588586   929511001  0.059305                 2  \n",
       "588587   891322004  0.042356                 2  \n",
       "588588   918325001  0.043203                 1  \n",
       "588589   833459002  0.006763                 1  \n",
       "588590   898573003  0.033881                 2  \n",
       "\n",
       "[31788324 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "data_dask.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "232eb40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dask.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d12a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 19:07:47,524\tINFO worker.py:1509 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.11</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.1</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8266\" target=\"_blank\">http://127.0.0.1:8266</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8266', python_version='3.9.11', ray_version='2.0.1', ray_commit='03b6bc7b5a305877501110ec04710a9c57011479', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:65199', 'raylet_socket_name': 'tcp://127.0.0.1:63008', 'webui_url': '127.0.0.1:8266', 'session_dir': 'C:\\\\Users\\\\Marija\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2022-11-07_19-07-40_465195_12652', 'metrics_export_port': 62934, 'gcs_address': '127.0.0.1:64789', 'address': '127.0.0.1:64789', 'dashboard_agent_listen_port': 52365, 'node_id': '50aea6afc9c49315bb6326c13c8a233b9c2f65744c1f4ad77b3a8e30'})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MODIN_ENGINE\"] = \"ray\"  # Modin will use Ray\n",
    "\n",
    "import modin.pandas as pd\n",
    "import ray\n",
    "ray.init(runtime_env={'env_vars': {'__MODIN_AUTOIMPORT_PANDAS__': '1'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0277709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.7 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "data_modin_ray = mpd.read_csv('transactions_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31dc1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Modin will use Dask\n",
    "\n",
    "import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8209a6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.1 s\n",
      "Wall time: 53.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "data_modin_dask = mpd.read_csv('transactions_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7144b58e",
   "metadata": {},
   "source": [
    "Times:\n",
    "pandas - 1min 33sec\n",
    "dask - 46.3sec\n",
    "modin-ray  - 1min 1sec\n",
    "modin-dask - 53.2sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d3ab82",
   "metadata": {},
   "source": [
    "3.Perform basic validation on data columns : eg: remove special character , white spaces from the col name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9d7aee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_names_normalisation(columns):\n",
    "    columns = columns.str.replace(' ','_',regex=True)\n",
    "    columns = list(map(lambda x: re.sub('\\W+','', x),list(columns)))\n",
    "    columns = list(map(lambda x: x.strip('_'), list(columns)))\n",
    "    columns =list(map(lambda x: x.lower(), list(columns)))\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "24cf0e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t_dat', 'customer_id', 'article_id', 'price', 'sales_channel_id'], dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pandas.columns = column_names_normalisation(data_pandas.columns)\n",
    "data_pandas.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c434a9",
   "metadata": {},
   "source": [
    "4.As you already know the schema hence create a YAML file and write the column name in YAML file. --define separator of\n",
    "read and write file, column name in YAML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d82982bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "dataset_name: data_pandas\n",
    "file_name: transactions_train\n",
    "table_name: transactions_train\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - t_dat\n",
    "    - customer_id\n",
    "    - article_id\n",
    "    - price\n",
    "    - sales_channel_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb9e2a",
   "metadata": {},
   "source": [
    "\n",
    "5.Validate number of columns and column name of ingested file with YAML.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2d69917d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n"
     ]
    }
   ],
   "source": [
    "#I think think this should be done at the beginning of the task and not after the column normalisation,\n",
    "#so I'll use original columns\n",
    "\n",
    "\n",
    "with open('file.yaml','r') as yaml_file:\n",
    "    yml_file = yaml.safe_load(yaml_file)\n",
    "\n",
    "expected_cols = yml_file['columns']\n",
    "columns = list(data_pandas.columns)\n",
    "\n",
    "def check_column_match(columns, expected_cols):\n",
    "\n",
    "    if len(columns) == len(expected_col) and list(set(columns).difference(expected_col)) == []:\n",
    "        print(\"column name and column length validation passed\")\n",
    "        \n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        \n",
    "        missing_from_yaml = list(set(columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",missing_from_yaml)\n",
    "        \n",
    "        missing_from_data = list(set(expected_col).difference(columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_from_data)\n",
    "\n",
    "check_column_match(columns, expected_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3901a1",
   "metadata": {},
   "source": [
    "6.Write the file in pipe separated text file (|) in gz format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f89a41cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pandas.to_csv(\"transactions_train.txt.gz\", \n",
    "           index=False, \n",
    "           sep='|',\n",
    "           compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "223a5093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31788324"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pandas.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab45b300",
   "metadata": {},
   "source": [
    "7.Create a summary of the file:\n",
    "\n",
    "Total number of rows,\n",
    "\n",
    "total number of columns\n",
    "\n",
    "file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d32bd534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "class SIZE_UNIT(enum.Enum):\n",
    "   BYTES = 1\n",
    "   KB = 2\n",
    "   MB = 3\n",
    "   GB = 4\n",
    "    \n",
    "def convert_unit(size_in_bytes, unit):\n",
    "   \"\"\" Convert the size from bytes to other units like KB, MB or GB\"\"\"\n",
    "   if unit == SIZE_UNIT.KB:\n",
    "       return size_in_bytes/1024\n",
    "   elif unit == SIZE_UNIT.MB:\n",
    "       return size_in_bytes/(1024*1024)\n",
    "   elif unit == SIZE_UNIT.GB:\n",
    "       return size_in_bytes/(1024*1024*1024)\n",
    "   else:\n",
    "       return size_in_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bba94b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_file_size(file_name, size_type = SIZE_UNIT.BYTES ):\n",
    "   \"\"\" Get file in size in given unit like KB, MB or GB\"\"\"\n",
    "   size = os.path.getsize(file_name)\n",
    "   return convert_unit(size, size_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "77f2bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'transactions_train.txt.gz'\n",
    "# get file size in KB\n",
    "size = get_file_size(file_path, SIZE_UNIT.MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7b710eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 31788324\n",
      "Total number of columns: 5 \n",
      "FIle size: 568.0889711380005 MB\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of rows: {data_pandas.shape[0]}\\nTotal number of columns: {data_pandas.shape[1]} \\nFIle size: {size} MB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
