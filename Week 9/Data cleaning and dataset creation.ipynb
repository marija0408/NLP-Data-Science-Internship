{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70745d6e",
   "metadata": {},
   "source": [
    "First thing I have to do is to create a dataset with all of the messages. During the reading I'll make sure to drop all the \\n signs, from and subject parts of the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e3563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4bd47f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'Data cleaning and dataset creation.ipynb',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d7e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = [\n",
    " 'alt.atheism',\n",
    " 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x',\n",
    " 'misc.forsale',\n",
    " 'rec.autos',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'sci.crypt',\n",
    " 'sci.electronics',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'soc.religion.christian',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.politics.misc',\n",
    " 'talk.religion.misc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "115b7d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dir alt.atheism\n",
      "Processing dir comp.graphics\n",
      "Processing dir comp.os.ms-windows.misc\n",
      "Processing dir comp.sys.ibm.pc.hardware\n",
      "Processing dir comp.sys.mac.hardware\n",
      "Processing dir comp.windows.x\n",
      "Processing dir misc.forsale\n",
      "Processing dir rec.autos\n",
      "Processing dir rec.motorcycles\n",
      "Processing dir rec.sport.baseball\n",
      "Processing dir rec.sport.hockey\n",
      "Processing dir sci.crypt\n",
      "Processing dir sci.electronics\n",
      "Processing dir sci.med\n",
      "Processing dir sci.space\n",
      "Processing dir soc.religion.christian\n",
      "Processing dir talk.politics.guns\n",
      "Processing dir talk.politics.mideast\n",
      "Processing dir talk.politics.misc\n",
      "Processing dir talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "class_index = []\n",
    "curr_class_index = 0\n",
    "for dr in dir_list:\n",
    "    print(f'Processing dir {dr}')\n",
    "    for file in os.listdir(dr):\n",
    "        f = open(f'{dr}/{file}', encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        lines = content.split(\"\\n\")\n",
    "        lines = lines[3:]\n",
    "        content = \" \".join(lines).replace('\\t','')\n",
    "        messages.append(content)\n",
    "        class_index.append(curr_class_index)\n",
    "    curr_class_index+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd38c16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18828"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecd68e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = list(range(0,18828))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32ca93b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(zip(id_col, messages,class_index)),\n",
    "               columns =['id', 'message','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38cca302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>In article &lt;C6697n.33o@panix.com&gt;, carlf@panix...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>CALL FOR PRESENTATIONS        NAVY SCIENTIFIC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>800</td>\n",
       "      <td>gnuplot, etc. make it easy to plot real valued...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            message  class\n",
       "798  798  In article <C6697n.33o@panix.com>, carlf@panix...      0\n",
       "799  799   CALL FOR PRESENTATIONS        NAVY SCIENTIFIC...      1\n",
       "800  800  gnuplot, etc. make it easy to plot real valued...      1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[798:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acb39a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('newsgroup_data',index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace03d29",
   "metadata": {},
   "source": [
    "After saving the dataframe for future use, the next step is to try a featurisation technique. \n",
    "I have found this one on the nlp tutorial: https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2c1d186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18828, 170988)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data.message)\n",
    "print(X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f83f0f8",
   "metadata": {},
   "source": [
    "Just counting the number of words in each document has 1 issue: it will give more weightage to longer documents than shorter documents. To avoid this, we can use frequency (TF - Term Frequencies) i.e. #count(word) / #Total words, in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "611d5f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18828, 170988)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ca8b0c",
   "metadata": {},
   "source": [
    "We get the same result, but it's good that we checked this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86575d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
